{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error Tunnel connection\n",
      "[nltk_data]     failed: 407 Proxy Authentication Required>\n",
      "[nltk_data] Error loading punkt_tab: <urlopen error Tunnel connection\n",
      "[nltk_data]     failed: 407 Proxy Authentication Required>\n",
      "Some weights of the model checkpoint at facebook/dpr-question_encoder-single-nq-base were not used when initializing DPRQuestionEncoder: ['question_encoder.bert_model.pooler.dense.bias', 'question_encoder.bert_model.pooler.dense.weight']\n",
      "- This IS expected if you are initializing DPRQuestionEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DPRQuestionEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at facebook/dpr-ctx_encoder-single-nq-base were not used when initializing DPRContextEncoder: ['ctx_encoder.bert_model.pooler.dense.bias', 'ctx_encoder.bert_model.pooler.dense.weight']\n",
      "- This IS expected if you are initializing DPRContextEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DPRContextEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
      "The class this function is called from is 'DPRContextEncoderTokenizer'.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from transformers import DPRQuestionEncoder, DPRContextEncoder, DPRQuestionEncoderTokenizer, DPRContextEncoderTokenizer\n",
    "from transformers import BartForConditionalGeneration, BartTokenizer\n",
    "import torch\n",
    "\n",
    "from  chunking import Chunking\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = \"cuda:1\"\n",
    "# Download NLTK data\n",
    "# I had to export as an env var where the data were downloaded : export NLTK_DATA=/home/hay4hi/nltk_data\n",
    "nltk.set_proxy('http://rb-proxy-de.bosch.com:8080')\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# Load retriever models and tokenizers\n",
    "question_encoder = DPRQuestionEncoder.from_pretrained('facebook/dpr-question_encoder-single-nq-base').to(device)\n",
    "context_encoder = DPRContextEncoder.from_pretrained('facebook/dpr-ctx_encoder-single-nq-base').to(device)\n",
    "question_tokenizer = DPRQuestionEncoderTokenizer.from_pretrained('facebook/dpr-question_encoder-single-nq-base')\n",
    "context_tokenizer = DPRContextEncoderTokenizer.from_pretrained('facebook/dpr-ctx_encoder-single-nq-base')\n",
    "\n",
    "# Load generator model and tokenizer\n",
    "generator = BartForConditionalGeneration.from_pretrained('facebook/bart-large').to(device)\n",
    "generator_tokenizer = BartTokenizer.from_pretrained('facebook/bart-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\nParis is the capital of France. It is known for its art, fashion, and culture.', 'It is known for its art, fashion, and culture. The Eiffel Tower is one of the most famous landmarks in Paris.', 'The Eiffel Tower is one of the most famous landmarks in Paris. Berlin is the capital of Germany.', 'Berlin is the capital of Germany. It has a rich history and is known for its museums and historical sites.', 'It has a rich history and is known for its museums and historical sites. Madrid is the capital of Spain.', 'Madrid is the capital of Spain. It is famous for its vibrant nightlife and cultural heritage.']\n",
      "768\n",
      "{'input_ids': tensor([[ 101, 3000, 2003, 1996, 3007, 1997, 2605, 1012, 2009, 2003, 2124, 2005,\n",
      "         2049, 2396, 1010, 4827, 1010, 1998, 3226, 1012,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "{'input_ids': tensor([[  101,  2009,  2003,  2124,  2005,  2049,  2396,  1010,  4827,  1010,\n",
      "          1998,  3226,  1012,  1996,  1041, 13355,  2884,  3578,  2003,  2028,\n",
      "          1997,  1996,  2087,  3297, 16209,  1999,  3000,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1]])}\n",
      "{'input_ids': tensor([[  101,  1996,  1041, 13355,  2884,  3578,  2003,  2028,  1997,  1996,\n",
      "          2087,  3297, 16209,  1999,  3000,  1012,  4068,  2003,  1996,  3007,\n",
      "          1997,  2762,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "{'input_ids': tensor([[ 101, 4068, 2003, 1996, 3007, 1997, 2762, 1012, 2009, 2038, 1037, 4138,\n",
      "         2381, 1998, 2003, 2124, 2005, 2049, 9941, 1998, 3439, 4573, 1012,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "{'input_ids': tensor([[ 101, 2009, 2038, 1037, 4138, 2381, 1998, 2003, 2124, 2005, 2049, 9941,\n",
      "         1998, 3439, 4573, 1012, 6921, 2003, 1996, 3007, 1997, 3577, 1012,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "{'input_ids': tensor([[  101,  6921,  2003,  1996,  3007,  1997,  3577,  1012,  2009,  2003,\n",
      "          3297,  2005,  2049, 17026,  2305, 15509,  1998,  3451,  4348,  1012,\n",
      "           102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "# Example large document\n",
    "large_document = \"\"\"\n",
    "Paris is the capital of France. It is known for its art, fashion, and culture. The Eiffel Tower is one of the most famous landmarks in Paris.\n",
    "Berlin is the capital of Germany. It has a rich history and is known for its museums and historical sites.\n",
    "Madrid is the capital of Spain. It is famous for its vibrant nightlife and cultural heritage.\n",
    "\"\"\"\n",
    "chunker = Chunking()\n",
    "\n",
    "# Step 1: Divide the text into chunks (e.g., sentences)\n",
    "#chunker.chunking_into_sentences(large_document)\n",
    "chunker.chunking_sliding_window(large_document, window_size=2, stride=1)\n",
    "chunks = chunker.chunks\n",
    "print(chunks)\n",
    "\n",
    "# Step 2: Encode the chunks using the context encoder\n",
    "chunk_embeddings = [context_encoder(**context_tokenizer(chunk, return_tensors='pt').to(device)).pooler_output for chunk in chunks]\n",
    "print(len((chunk_embeddings[0].cpu().detach().numpy()[0])))\n",
    "\n",
    "for chunk in chunks:\n",
    "    print(context_tokenizer(chunk, return_tensors='pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input query\n",
    "query = \"What is the capital of France?\"\n",
    "\n",
    "# Step 3: Encode the query using the question encoder\n",
    "query_embedding = question_encoder(**question_tokenizer(query, return_tensors='pt').to(device)).pooler_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([0.7176], device='cuda:1', grad_fn=<SumBackward1>), tensor([0.6171], device='cuda:1', grad_fn=<SumBackward1>), tensor([0.6185], device='cuda:1', grad_fn=<SumBackward1>), tensor([0.5604], device='cuda:1', grad_fn=<SumBackward1>), tensor([0.6354], device='cuda:1', grad_fn=<SumBackward1>), tensor([0.6012], device='cuda:1', grad_fn=<SumBackward1>)]\n",
      "tensor([[ 3.7717e-01, -3.6294e-01, -1.4239e-01, -8.1584e-02, -8.7463e-02,\n",
      "          2.4833e-01,  2.7685e-01,  9.0941e-01, -6.2721e-01, -6.8360e-01,\n",
      "         -6.7071e-01, -8.6989e-02, -3.4711e-02,  6.0646e-01,  1.6714e-01,\n",
      "          7.1914e-02,  6.4191e-01,  2.1475e-01,  1.4365e-01, -5.6612e-02,\n",
      "         -6.9641e-01,  2.2993e-01,  1.6472e-01, -3.0849e-01,  3.7029e-01,\n",
      "         -4.5719e-01, -5.9384e-01,  2.6634e-02,  1.7385e-01,  3.4582e-01,\n",
      "         -9.9865e-02, -2.4540e-01, -5.0825e-01, -1.2908e-02,  1.1949e-01,\n",
      "         -1.4771e-01,  1.4425e-01, -1.6174e-01,  1.9517e-01, -4.3521e-01,\n",
      "          4.1186e-02, -4.7788e-01,  5.6292e-01,  9.7015e-02, -4.1153e-01,\n",
      "         -5.6134e-01, -7.2298e-01,  1.0237e+00, -2.6897e-01,  3.0750e-01,\n",
      "         -3.0439e-01,  2.1458e-01, -4.0270e-02,  8.9342e-01,  2.5248e-01,\n",
      "          2.8246e-01, -1.0882e+00,  3.4580e-01, -1.6620e-01, -1.4299e-01,\n",
      "          2.6429e-01,  5.9827e-01,  1.8844e-01,  3.2498e-01,  9.0936e-02,\n",
      "          2.1986e-01,  3.7604e-01, -5.7187e-01,  4.4563e-01, -2.1910e-01,\n",
      "         -4.4878e-02, -1.6527e-01, -1.8475e-01,  1.3377e-01, -9.0248e-01,\n",
      "         -9.8465e-02, -2.5188e-01, -3.7199e-03,  4.7829e-01,  1.1336e-01,\n",
      "          4.6079e-01, -2.3438e-01,  6.2320e-01,  2.2279e-01,  4.2046e-01,\n",
      "          4.9454e-01, -4.5249e-01,  2.2419e-01, -4.8765e-01, -2.7419e-01,\n",
      "         -5.0120e-01,  1.8881e-01,  6.4941e-01, -1.7985e-01, -1.2697e-01,\n",
      "         -2.0297e-01,  4.2644e-01, -9.9115e-02,  4.1231e-02, -3.1911e-01,\n",
      "         -1.9691e-01,  1.3304e-01,  2.5902e-01,  2.2732e-01,  1.6190e-02,\n",
      "         -5.1511e-01, -5.2661e-01, -1.2984e-01,  1.4501e-02,  7.0274e-02,\n",
      "         -2.2171e-01, -1.3844e-01, -3.0946e-01, -2.6759e-01, -1.7376e-02,\n",
      "          4.2346e-01,  3.7006e-01,  4.0979e-02, -5.5981e-02, -3.6491e-02,\n",
      "         -8.9284e-03, -6.2073e-02,  3.8204e-01,  7.2282e-02, -1.7539e-01,\n",
      "         -1.7827e-01,  7.5331e-01,  5.7981e-01, -5.6469e-02, -7.7000e-02,\n",
      "         -2.3666e-02,  4.9760e-01, -4.7494e-01, -1.6616e-01,  4.6905e-01,\n",
      "         -9.6715e-01,  2.9686e-01,  2.9326e-01,  2.0539e-01,  1.7856e-01,\n",
      "         -4.1203e-01, -8.1134e-02, -1.4389e-01,  1.5398e-02, -1.1200e-01,\n",
      "         -7.0190e-01, -1.8476e-01, -5.4861e-01,  2.2032e-01, -3.5329e-01,\n",
      "          2.0971e-01,  2.7164e-01, -2.7374e-01, -4.6356e-01, -1.0318e-01,\n",
      "         -4.8009e-01,  8.3436e-01,  3.1207e-01,  4.3867e-01,  1.8276e-01,\n",
      "          6.4773e-01, -2.7370e-01,  7.4335e-01, -2.5596e-01, -2.6983e-01,\n",
      "          6.6897e-03,  2.5939e-01,  5.0991e-01, -3.6664e-01,  1.4400e-01,\n",
      "         -6.1172e-01,  1.4386e-01,  7.9229e-01, -1.1103e-01, -2.1553e-01,\n",
      "          4.8982e-01,  4.5794e-01,  2.1476e-01,  5.0410e-01,  8.0917e-02,\n",
      "         -4.2601e-01,  2.7837e-01,  3.7890e-02,  2.1033e-01,  9.1286e-01,\n",
      "         -3.1808e-01,  4.0847e-01,  1.2990e-03,  3.0397e-01,  7.7811e-02,\n",
      "         -2.1528e-01, -1.0673e-01, -7.3091e-01, -7.2838e-01,  6.1274e-01,\n",
      "         -2.8891e-01, -1.0280e-01,  8.3757e-01, -6.0079e-02,  5.5099e-01,\n",
      "         -6.3757e-01, -7.7167e-02,  8.8739e-01, -7.5925e-02, -9.1787e-01,\n",
      "         -2.7544e-01,  2.2183e-01, -6.2276e-02,  1.3080e-01,  2.0687e-01,\n",
      "          5.2581e-01, -6.9002e-01,  6.9646e-02,  2.1230e-01,  7.1692e-04,\n",
      "         -2.9607e-01, -5.7899e-01, -2.4969e-01,  4.0151e-02, -1.0010e-01,\n",
      "          8.2835e-01, -8.7816e-03, -2.0571e-01, -1.6332e-03, -4.9176e-01,\n",
      "         -9.2549e-02,  1.0626e-01, -1.6310e-01, -9.3971e-02, -1.5123e-01,\n",
      "         -4.7212e-01, -1.2481e-01, -2.5681e-01, -2.2333e-01, -5.1247e-01,\n",
      "          7.3644e-03, -1.7717e-01, -3.0584e-01,  4.0012e-01, -6.4983e-01,\n",
      "          6.2628e-01,  1.5081e-01,  4.2989e-01,  6.4985e-01,  1.0519e-01,\n",
      "          5.2204e-01,  3.2021e-02,  2.1127e-01, -1.8117e-01, -9.3061e-02,\n",
      "         -5.3017e-01,  2.3355e-01, -9.2542e-02,  7.0447e-02,  2.0159e-02,\n",
      "         -8.7795e-01,  6.0282e-01,  6.7125e-01,  3.2707e-01,  3.5071e-01,\n",
      "         -1.5952e-02, -8.5751e-01, -8.6228e-02,  5.5151e-01, -1.7441e-01,\n",
      "         -3.4838e-01, -2.0673e-01, -5.9323e-01,  7.8958e-01,  7.6905e-01,\n",
      "          1.9022e-01, -2.0270e-01, -2.2816e-01,  1.0641e-01,  1.1648e-01,\n",
      "          1.7105e-01,  3.8974e-03,  5.7129e-01, -2.2721e-01,  1.2312e-01,\n",
      "          2.5378e-01,  7.6973e-01, -4.0315e-01, -9.9515e-01, -3.6490e-01,\n",
      "         -4.4886e-01,  2.2355e-01, -6.5113e-01, -2.6102e-01,  2.5415e-01,\n",
      "         -4.4215e-02, -3.8036e-01, -2.6014e-01, -3.6599e-01, -1.8722e-01,\n",
      "         -7.7965e-01,  2.5313e-01,  1.7857e-01, -2.3636e-01, -4.7410e-01,\n",
      "         -4.5272e-01,  4.5795e-01,  4.0096e-01,  2.4479e-01,  9.5031e-01,\n",
      "         -3.9361e-01,  3.1093e-01,  1.4355e-01, -5.6847e+00, -2.3645e-01,\n",
      "          4.6846e-01,  5.9949e-03, -2.4245e-01,  1.6076e-01,  3.0442e-01,\n",
      "          2.1096e-01, -2.6549e-01, -6.7137e-01,  3.0255e-02, -9.8102e-02,\n",
      "         -2.1568e-01,  8.2821e-01, -1.6658e-01,  7.2513e-01,  4.3183e-02,\n",
      "          4.2005e-02, -2.2019e-01,  2.5559e-01, -6.6291e-01, -2.9512e-01,\n",
      "          3.2268e-01,  3.2319e-01,  2.5414e-01,  1.1524e-01, -5.7248e-01,\n",
      "         -2.8047e-01, -8.6035e-01, -4.5347e-01, -1.2799e-01,  1.2654e-02,\n",
      "          8.0936e-01, -6.4148e-01,  5.5734e-01, -3.8149e-01,  2.1369e-01,\n",
      "         -5.2210e-01, -6.0434e-01, -4.2494e-01,  3.1722e-01,  5.9457e-01,\n",
      "         -1.9953e-01, -1.3025e-01,  6.4715e-01, -5.2123e-01, -4.7309e-01,\n",
      "          1.6462e-01, -1.6018e-01,  2.1046e-01, -4.4625e-02,  1.0915e-01,\n",
      "         -3.7737e-01, -4.9459e-01, -2.8776e-01, -2.8931e-01,  7.0709e-01,\n",
      "          3.6762e-01, -3.7588e-01,  2.8656e-01,  6.7190e-02,  9.2554e-02,\n",
      "          1.1000e-01,  6.3786e-02,  1.6521e-01, -2.7361e-01, -7.4919e-01,\n",
      "          6.2337e-01, -3.0514e-01,  4.2167e-01, -1.4947e-01,  4.0138e-02,\n",
      "         -2.3375e-01, -8.0908e-01, -5.1879e-01, -6.4258e-01, -4.6188e-01,\n",
      "         -1.3763e-01,  2.6941e-01,  6.6475e-02, -5.4050e-01, -1.4542e-01,\n",
      "          1.2605e-02,  4.0590e-02, -1.6351e-01, -4.3072e-01, -2.4009e-01,\n",
      "          2.4932e-01,  4.3024e-02, -3.7018e-01,  3.6227e-01, -5.7075e-01,\n",
      "          7.7593e-01, -3.5736e-01,  6.6485e-02, -2.7960e-01,  2.3145e-01,\n",
      "         -3.0458e-01,  4.2265e-01, -4.9666e-02,  3.2470e-02, -1.1953e-02,\n",
      "         -2.9268e-01,  3.6555e-01,  2.0567e-01, -5.9388e-02,  4.5359e-01,\n",
      "          8.2288e-01,  1.1629e+00, -4.7654e-01, -5.8722e-01,  7.9874e-02,\n",
      "         -2.8849e-01, -3.4759e-01,  6.7615e-01, -1.1254e+00, -4.8729e-01,\n",
      "          4.4266e-01,  5.0729e-02, -2.3285e-02, -2.0263e-01,  6.7178e-01,\n",
      "         -5.9184e-01,  5.2172e-01,  1.6992e-02,  9.7895e-02, -3.8400e-01,\n",
      "         -1.8898e-01,  8.2372e-02, -1.4195e-01, -7.0176e-02,  3.6469e-01,\n",
      "          4.2351e-01, -4.9127e-03,  5.9121e-01, -2.8699e-01,  1.2489e-01,\n",
      "         -4.8120e-01,  3.1149e-01, -5.4961e-01,  4.6249e-01,  8.3269e-01,\n",
      "          1.9593e-01,  5.0291e-01,  7.8537e-01,  3.2491e-01, -6.2368e-02,\n",
      "          2.6870e-01,  1.4330e-01,  6.7765e-02,  5.2526e-01,  3.7749e-01,\n",
      "          1.9106e-01,  4.7620e-01, -2.5782e-01, -1.0420e-01,  1.1999e-01,\n",
      "          7.1286e-01,  2.5528e-03, -1.5747e-01,  5.3860e-01, -6.7757e-01,\n",
      "         -9.8281e-01,  1.2932e-01,  4.9152e-01, -4.9248e-01, -2.1877e-01,\n",
      "         -1.8322e-01, -5.4929e-02, -4.3888e-02,  8.0809e-01, -3.1991e-01,\n",
      "          3.2321e-01, -5.5225e-01, -5.6551e-01, -3.9847e-01,  8.9089e-02,\n",
      "          3.8896e-01,  3.7808e-02, -1.4895e-01,  3.5600e-01, -4.9355e-01,\n",
      "         -8.0086e-02,  3.9556e-01,  8.8344e-02, -1.0480e-01,  1.1508e-01,\n",
      "         -1.4772e-01,  1.6336e-01, -4.8778e-02,  4.1777e-01,  2.2924e-01,\n",
      "         -1.1101e+00,  1.0580e-01, -7.2061e-01, -5.8760e-01, -2.4824e-01,\n",
      "         -7.9867e-02, -5.3667e-01,  4.0017e-01, -3.0106e-01,  3.1471e-01,\n",
      "         -2.2035e-01,  5.2327e-02,  2.9776e-01, -1.8522e-01,  9.6996e-01,\n",
      "          3.9724e-01,  1.7189e-01, -4.9096e-02, -1.1038e+00, -1.0202e-01,\n",
      "          3.6679e-01,  1.7181e-01, -5.6084e-01, -1.4187e-01,  3.8352e-03,\n",
      "         -5.6111e-01, -1.2612e-01, -3.2247e-01,  1.2282e-01, -2.3526e-01,\n",
      "          8.5529e-02, -2.9778e-01, -7.1129e-02,  9.2285e-01,  5.5243e-01,\n",
      "         -1.8481e-01,  1.0532e-01, -1.0700e+00,  4.2407e-01,  4.2092e-01,\n",
      "         -1.0890e-01, -1.5638e-01, -3.6914e-01, -3.1601e-01,  3.9997e-01,\n",
      "         -2.3441e-01,  3.4583e-01, -1.8094e-01,  2.4112e-01,  5.2285e-01,\n",
      "         -4.2485e-01,  3.1087e-01, -2.7168e-01,  2.1003e-01,  3.2642e-01,\n",
      "         -1.7606e-01, -3.6560e-01,  3.9706e-02, -3.6954e-01, -4.1977e-01,\n",
      "         -2.0814e-01, -1.9932e-01, -2.1464e-01, -5.5455e-01,  4.5168e-02,\n",
      "          5.8201e-01, -1.5203e-01,  3.0698e-01, -2.2572e-01, -3.3918e-01,\n",
      "         -5.7794e-01,  1.4207e-01,  5.5026e-01, -1.5161e-01, -8.0011e-02,\n",
      "         -3.2563e-02, -3.3420e-01, -3.8838e-01, -2.3180e-01, -5.1332e-01,\n",
      "          6.5727e-02, -1.9183e-01,  5.3740e-01,  1.1661e-01, -4.4988e-01,\n",
      "          1.6819e-01,  3.9110e-01,  5.8230e-02, -4.0443e-01,  2.9009e-01,\n",
      "          6.5920e-02, -4.8243e-01,  8.7086e-01, -9.0266e-01,  1.5911e-01,\n",
      "          4.2529e-01, -6.3498e-01,  4.3211e-01,  1.0599e-01, -5.7631e-01,\n",
      "          3.9433e-01,  3.6113e-01,  8.0262e-02,  4.4490e-01,  1.8869e-01,\n",
      "          8.4163e-01,  6.3643e-02,  4.9868e-01, -6.0512e-01,  3.7746e-01,\n",
      "          3.2873e-01, -7.7449e-01, -2.0788e-02,  2.1268e-03,  6.9840e-02,\n",
      "         -4.0234e-01,  2.2473e-01,  4.2020e-01,  2.4014e-01,  1.4029e-01,\n",
      "         -3.6781e-01,  2.9822e-02, -5.7762e-01,  8.0613e-01,  5.9169e-01,\n",
      "         -7.1946e-01,  3.9441e-01,  3.6850e-02, -4.6948e-01,  9.8186e-03,\n",
      "          2.1295e-01,  9.8531e-02,  5.5800e-03,  4.4918e-01, -2.4496e-01,\n",
      "          3.4251e-01,  2.5304e-01,  1.5563e-01,  2.8362e-01,  7.0511e-01,\n",
      "         -7.5814e-01,  5.8019e-01, -7.4328e-01, -3.5540e-01,  4.9048e-03,\n",
      "         -2.6085e-02,  1.3405e-01, -2.0648e-01,  1.2717e+00,  1.4467e-01,\n",
      "         -8.5855e-01,  4.3077e-01,  1.2349e-01,  1.2336e-01, -8.3877e-02,\n",
      "         -2.3995e-01, -1.1168e-01, -7.0629e-02,  6.5996e-01, -2.4193e-01,\n",
      "         -1.5431e-02,  2.3285e-01,  7.1888e-01, -4.1225e-01, -1.5000e-01,\n",
      "         -2.1520e-02,  2.7276e-01,  8.7230e-02,  1.5105e-02,  2.2392e-01,\n",
      "          1.9546e-01,  4.1039e-01, -4.5468e-01,  3.2401e-01,  3.0906e-01,\n",
      "         -3.4317e-01, -3.4722e-01, -1.9746e-01, -1.9882e-01,  5.2060e-01,\n",
      "         -6.1920e-02, -6.1111e-01,  3.4868e-01,  2.8141e-01, -5.9780e-03,\n",
      "          5.3824e-02,  4.7772e-02, -3.2671e-01, -1.3814e-01, -5.7626e-01,\n",
      "         -7.2109e-01, -2.2982e-01, -1.6294e-02,  4.0489e-01, -7.7279e-02,\n",
      "         -7.4371e-02, -7.2386e-01, -2.6575e-01, -4.2124e-01,  4.1564e-02,\n",
      "          1.6730e-01, -4.3196e-02,  3.2722e-02, -3.1133e-01,  1.8005e-01,\n",
      "          4.5124e-01, -5.2228e-01,  7.3507e-02,  7.0625e-01,  4.4610e-02,\n",
      "         -1.8010e-01,  2.7692e-03,  4.0172e-01,  3.9090e-01,  6.5516e-02,\n",
      "         -2.2589e-01, -6.7980e-01,  8.5527e-02,  4.0987e-02, -2.8391e-01,\n",
      "         -1.4117e-01,  5.1375e-01,  2.3902e-01, -1.6222e-02,  3.2198e-02,\n",
      "         -2.2290e-01,  9.2413e-02, -8.0354e-01,  1.8469e-01, -9.9550e-02,\n",
      "          2.0103e-01,  7.5164e-01, -2.3361e-01, -5.8927e-01,  3.0107e-01,\n",
      "          3.2895e-01, -1.0770e-01,  4.6202e-01, -1.3997e-01, -2.7525e-02,\n",
      "         -4.2899e-01,  3.1459e-01, -7.5683e-01, -2.7053e-01,  4.9959e-01,\n",
      "          6.1041e-01, -5.2746e-01, -4.6607e-01, -2.3205e-01,  3.8508e-01,\n",
      "          6.1710e-02,  1.1722e-01, -1.9966e-02,  5.3392e-02, -6.4869e-01,\n",
      "          2.3672e-01, -7.8749e-01,  1.3979e-01,  1.1935e-01,  2.6987e-01,\n",
      "          5.8791e-01, -1.3588e-01,  3.0521e-01,  5.9227e-03,  7.9304e-01,\n",
      "         -6.8895e-01,  6.9492e-01,  1.3286e-01]], device='cuda:1',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([[-5.2156e-03, -1.5852e-01,  2.0611e-02,  3.4767e-02,  1.2007e-01,\n",
      "          1.4229e-01,  9.5774e-02,  4.3038e-01, -4.1209e-01, -1.9872e-01,\n",
      "         -3.0230e-01, -1.7457e-02, -8.9081e-02, -5.8298e-04,  1.0536e-01,\n",
      "         -3.0328e-02,  8.9062e-02, -1.7427e-01,  2.8431e-01, -2.2887e-02,\n",
      "         -2.2067e-01,  2.5106e-01, -1.0152e-01, -1.8617e-01,  2.6942e-01,\n",
      "         -3.3481e-01, -1.2376e-01,  1.5540e-01,  5.9243e-02,  3.6197e-02,\n",
      "         -1.2335e-01, -1.1681e-01, -1.3104e-01, -2.5730e-02,  2.5892e-01,\n",
      "          5.4344e-02,  2.3202e-02, -1.2395e-01, -7.8749e-02, -8.7373e-02,\n",
      "         -5.6473e-02, -2.5955e-01,  2.6724e-01, -2.7687e-01, -1.5055e-01,\n",
      "          4.1343e-02,  2.1680e-02,  6.0134e-01,  3.0130e-01,  1.1802e-01,\n",
      "         -8.6408e-02,  1.5915e-01,  1.0032e-01,  4.2424e-01, -1.5780e-02,\n",
      "          5.3884e-02, -3.4065e-01, -1.7087e-01, -1.1048e-03, -2.4550e-02,\n",
      "         -8.6235e-02,  1.7591e-01,  4.9632e-02,  1.6214e-01, -5.1496e-02,\n",
      "          1.7773e-02,  2.9060e-01, -1.4007e-01, -3.2634e-01,  2.5887e-02,\n",
      "          6.1434e-02,  1.0677e-01, -1.3496e-01,  3.9292e-02, -5.0723e-01,\n",
      "         -1.8477e-02, -1.2611e-01,  1.3390e-01,  1.0912e-01, -4.5382e-02,\n",
      "         -1.0848e-01, -4.2958e-03,  3.7400e-01, -2.9170e-01,  3.0176e-01,\n",
      "          4.8247e-01, -1.4428e-01,  1.5677e-01, -6.0631e-02, -9.3523e-02,\n",
      "         -1.9082e-01, -2.2454e-01, -2.2325e-01, -3.1785e-01, -2.7073e-03,\n",
      "         -5.6664e-02,  2.5148e-01,  9.6772e-02,  5.0339e-02,  2.0590e-01,\n",
      "         -1.2531e-01,  2.8710e-01,  2.6648e-01,  3.7141e-01,  1.1838e-01,\n",
      "          4.9583e-02, -6.6391e-02, -9.6638e-02, -1.7529e-02,  1.6047e-01,\n",
      "          5.2597e-02, -6.8556e-02, -1.3891e-01, -1.8370e-01,  8.4956e-02,\n",
      "          2.0864e-01,  3.3702e-01, -6.7968e-03,  2.0882e-01, -1.4547e-02,\n",
      "         -9.9242e-02, -1.3618e-01,  4.7241e-02,  1.4403e-01,  1.5245e-01,\n",
      "         -1.5116e-01,  1.6445e-01,  1.8973e-01, -1.6511e-03, -3.8305e-01,\n",
      "          2.3700e-01, -9.0752e-02, -2.5438e-01, -1.6952e-04,  3.8801e-01,\n",
      "         -2.3322e-01, -1.7931e-01, -7.7338e-02,  2.3773e-01,  3.2791e-02,\n",
      "         -5.9782e-02,  2.7011e-01, -4.0050e-02,  1.7911e-01,  5.2914e-02,\n",
      "         -2.5473e-01, -1.1240e-01,  1.7300e-01,  2.7928e-01, -1.5442e-01,\n",
      "          3.8183e-03,  2.7543e-01,  4.7058e-03, -2.1833e-01, -2.6759e-01,\n",
      "         -5.7223e-01,  2.2743e-01,  1.2375e-01,  7.9578e-02,  3.0092e-02,\n",
      "          3.1355e-01, -1.2810e-02,  3.4701e-01, -2.6334e-02,  7.1602e-02,\n",
      "          2.8581e-02,  1.5004e-01,  1.1292e-01, -1.8744e-01, -1.0991e-01,\n",
      "         -3.5729e-01, -1.0206e-01,  5.4687e-01, -2.1326e-01,  6.8124e-02,\n",
      "         -1.0651e-02,  3.2260e-01, -2.3207e-01,  3.7237e-02,  2.3658e-01,\n",
      "         -3.5038e-02,  2.1704e-01, -6.1375e-02,  1.2017e-01,  2.3832e-01,\n",
      "         -9.0574e-02,  2.1322e-01, -1.9250e-01,  7.4291e-02, -5.1613e-03,\n",
      "          5.8065e-02, -3.0846e-01, -2.8160e-01, -6.6830e-02, -1.1399e-01,\n",
      "         -6.2576e-02,  1.4720e-01,  3.5337e-01,  3.6239e-02, -3.3842e-02,\n",
      "         -4.4292e-01,  9.3553e-02,  5.7535e-01, -1.2151e-02, -1.1655e-01,\n",
      "         -6.0389e-02, -1.6024e-01, -2.3132e-01, -1.4592e-01,  1.7203e-01,\n",
      "          2.8436e-02, -1.5136e-01,  2.8875e-01,  3.5900e-01,  1.2755e-01,\n",
      "         -2.1075e-01, -1.9321e-01, -1.6896e-01,  8.0070e-02,  3.3915e-01,\n",
      "          4.7617e-03, -7.1142e-02, -1.6811e-01,  4.8252e-01, -2.2939e-01,\n",
      "         -1.3952e-01,  1.6639e-01, -2.0797e-01, -3.2743e-01, -1.1470e-01,\n",
      "         -3.7829e-01,  3.2065e-03, -1.9917e-01, -6.3350e-02, -2.8816e-01,\n",
      "          2.4830e-01, -1.0446e-01, -1.4797e-01,  1.2369e-01, -2.3197e-01,\n",
      "          3.4566e-01, -3.2861e-02,  4.8702e-01,  2.6729e-01,  2.0851e-01,\n",
      "          2.1713e-01,  2.2642e-01,  4.5769e-01,  1.7808e-01,  2.9189e-02,\n",
      "         -2.7367e-01, -8.3310e-02, -2.8762e-02, -9.6855e-02, -8.2211e-02,\n",
      "         -2.5991e-01,  5.5192e-01,  6.4200e-01,  1.8533e-01,  5.5763e-02,\n",
      "         -2.7463e-01, -3.4842e-01, -1.0126e-01,  2.6898e-01,  1.1298e-03,\n",
      "         -3.4809e-02, -3.6551e-02, -5.3044e-03,  3.0042e-01,  2.6304e-01,\n",
      "         -3.4653e-01,  1.2975e-02,  4.4136e-02,  9.6089e-02,  1.5279e-01,\n",
      "          4.2441e-01,  1.6030e-02,  4.4523e-01,  5.0219e-03,  2.3613e-01,\n",
      "         -1.7636e-01,  5.6773e-02, -2.3181e-01,  1.2031e-02,  1.3267e-01,\n",
      "         -9.0888e-02,  8.2885e-02, -3.5778e-01, -4.6588e-02, -7.6622e-03,\n",
      "         -1.3674e-02, -5.2053e-01, -2.0886e-01, -1.1235e-01, -1.8360e-01,\n",
      "         -4.8191e-01,  1.3931e-01, -1.3985e-01, -5.7385e-02, -8.0935e-02,\n",
      "         -4.5697e-02,  1.9066e-01,  3.8619e-01,  3.6819e-02,  4.0131e-01,\n",
      "         -6.0107e-02,  2.8186e-01,  8.0043e-02, -7.1891e+00, -1.4701e-01,\n",
      "          4.6090e-01, -1.1684e-01, -6.4799e-03,  6.2502e-02, -2.2893e-01,\n",
      "          8.4971e-02,  1.9238e-01, -2.5157e-01, -1.5108e-01, -1.9327e-01,\n",
      "         -3.6222e-01,  1.7992e-01,  1.6734e-01,  3.4660e-01, -9.8095e-02,\n",
      "         -2.0928e-01, -1.6777e-01, -1.1479e-01, -1.9214e-01,  3.8397e-01,\n",
      "          3.5845e-01,  2.1227e-01,  1.0281e-01, -1.7450e-01, -3.1915e-01,\n",
      "         -1.4050e-01, -4.3531e-01, -3.4838e-01,  1.0042e-01,  5.1072e-02,\n",
      "          2.0528e-01,  1.9892e-01,  2.3169e-01, -1.3375e-01,  2.2413e-01,\n",
      "         -2.1384e-01, -1.4834e-01, -7.4777e-02,  1.1818e-01,  3.4328e-01,\n",
      "          2.6302e-01,  1.1205e-01,  2.5062e-02, -2.4297e-01,  3.8751e-02,\n",
      "         -4.7417e-02, -9.4116e-03, -3.4643e-02, -5.6283e-02,  4.7900e-02,\n",
      "         -2.3639e-01, -2.8310e-01,  2.5321e-02,  2.3804e-02,  3.7552e-01,\n",
      "          3.6178e-01, -6.3175e-02,  5.3858e-02,  8.9393e-02,  3.0416e-01,\n",
      "         -1.8358e-01, -1.4953e-01, -6.7100e-02,  1.9020e-02, -3.9874e-01,\n",
      "          4.4659e-01, -5.1370e-02,  1.0373e-01,  8.0652e-02, -5.8666e-02,\n",
      "         -4.5625e-01, -4.6686e-01, -3.0942e-01, -2.1712e-01, -1.4838e-01,\n",
      "          7.5041e-02,  2.9845e-01,  1.8069e-01, -2.8885e-01,  1.9936e-01,\n",
      "          7.4423e-03, -5.1062e-02, -9.3340e-02, -1.6343e-01, -1.9237e-01,\n",
      "          1.7476e-01,  1.2383e-01,  1.7860e-01, -1.7011e-01, -9.8270e-02,\n",
      "          2.4797e-01, -7.9269e-02, -1.4763e-01, -2.3003e-01, -1.2739e-02,\n",
      "         -1.5375e-01, -1.9421e-01,  2.7800e-01, -1.2387e-01,  8.6612e-02,\n",
      "         -1.4758e-01,  1.4101e-01,  3.6996e-02,  9.7990e-03,  1.2864e-01,\n",
      "          3.1419e-01,  2.6410e-01,  1.9777e-01, -9.6147e-02, -6.4195e-02,\n",
      "         -9.5977e-02,  8.4152e-02,  2.1404e-01, -2.7428e-01, -1.5203e-01,\n",
      "          4.0712e-01, -8.4681e-02,  4.3436e-03, -1.8283e-01,  1.2275e-01,\n",
      "         -6.4359e-03,  2.8488e-01, -5.2476e-02, -4.4843e-02, -1.9809e-01,\n",
      "         -1.8747e-01, -9.9325e-02,  4.8412e-02, -1.0765e-01, -1.0962e-02,\n",
      "          1.8715e-01, -4.1873e-01,  2.2131e-01, -5.5813e-02, -2.4976e-02,\n",
      "         -5.8259e-02,  1.0904e-01,  2.0961e-01,  1.9814e-01,  4.0229e-01,\n",
      "          4.7574e-02,  1.1699e-01,  1.6113e-01, -1.2969e-02,  3.0397e-02,\n",
      "          1.1310e-01,  2.1106e-01,  1.2826e-01,  4.1413e-01,  3.6311e-01,\n",
      "          1.9514e-01,  3.1260e-01, -1.1471e-01, -9.5465e-02,  2.2701e-01,\n",
      "          3.6092e-01,  1.4514e-01,  2.1321e-01, -6.3111e-02, -3.4032e-01,\n",
      "          1.2540e-02, -1.8531e-02,  4.1996e-01, -8.3098e-02,  1.8995e-01,\n",
      "         -1.5536e-01, -4.9176e-03, -1.5145e-01,  3.7266e-01, -2.5406e-01,\n",
      "          1.6723e-02, -3.4013e-01, -3.6449e-01, -2.1806e-01,  2.7108e-01,\n",
      "          1.5930e-02, -2.0875e-02, -2.7170e-01,  1.9692e-02, -3.6589e-01,\n",
      "          1.2405e-01,  1.6110e-01, -5.8142e-03,  1.1788e-01,  1.0370e-01,\n",
      "         -1.1987e-01,  1.9373e-01, -1.7926e-01,  1.8657e-01,  2.3978e-01,\n",
      "         -4.7541e-01,  2.8355e-01, -2.5518e-01, -4.8838e-01,  1.0406e-02,\n",
      "         -3.2088e-01, -2.2495e-01,  2.0507e-01, -3.3621e-01, -1.0076e-01,\n",
      "          4.4003e-01,  4.4896e-03, -1.2905e-01,  2.5817e-01,  2.2066e-01,\n",
      "         -1.3193e-01,  4.0974e-02, -2.1112e-01, -3.0226e-01,  3.3264e-02,\n",
      "          2.5545e-01,  1.8148e-01, -1.3993e-01, -1.9878e-01, -5.8306e-03,\n",
      "         -3.2116e-01, -4.0875e-01,  2.4393e-02,  2.9808e-02, -9.7454e-02,\n",
      "          4.2256e-01,  8.2460e-03,  2.8251e-01,  5.9555e-01,  2.1591e-01,\n",
      "          1.0024e-01,  2.8040e-01, -3.0815e-01,  9.8542e-02,  4.0214e-01,\n",
      "          1.1162e-03, -1.4265e-01, -5.1305e-02, -1.3939e-01,  2.6402e-01,\n",
      "         -2.0818e-01,  5.8630e-02, -1.9120e-01,  2.8065e-01, -1.3696e-01,\n",
      "          1.1538e-01, -7.7823e-02, -5.6526e-02, -2.7408e-02,  1.5161e-01,\n",
      "          8.8029e-02, -2.2302e-02,  6.5527e-02, -5.5491e-01,  1.0026e-01,\n",
      "          6.8379e-02, -1.5971e-01,  4.8037e-02, -3.6525e-01, -2.6704e-02,\n",
      "          2.2424e-01, -1.0825e-01, -9.1830e-02, -3.9376e-01, -4.1458e-01,\n",
      "          1.2699e-01,  3.2970e-01,  8.5226e-02, -3.3022e-01, -6.7161e-02,\n",
      "          1.3883e-01,  1.1662e-01, -2.5395e-01, -1.4595e-01, -1.9309e-01,\n",
      "          8.6264e-02, -3.1896e-02,  2.3633e-01,  1.4000e-02, -1.2107e-01,\n",
      "          3.0165e-01,  2.7090e-01, -2.3018e-01, -1.8046e-01,  3.3335e-01,\n",
      "         -4.3704e-02, -1.3964e-01,  4.9766e-01, -1.4865e-01, -2.1948e-01,\n",
      "          2.0910e-01, -1.9626e-01,  1.6235e-01,  1.5837e-01, -3.6948e-01,\n",
      "          2.0153e-01,  2.7822e-01,  3.9343e-02,  7.1952e-02, -6.0999e-02,\n",
      "          5.1264e-01,  2.1267e-01,  1.1261e-01, -4.6622e-01, -1.6920e-01,\n",
      "          2.6376e-01, -3.7427e-01, -1.0021e-01,  1.5782e-01, -3.0400e-01,\n",
      "         -1.5881e-01,  1.0220e-02,  8.3663e-02,  1.8840e-01,  3.5708e-02,\n",
      "         -2.5563e-01, -1.0250e-01,  1.1042e-01,  4.2473e-01, -3.7765e-01,\n",
      "         -5.3039e-01, -1.0421e-01, -3.7260e-02, -2.9127e-01,  1.1506e-02,\n",
      "         -1.7211e-01,  2.5055e-01,  4.5192e-02,  1.1334e-01,  6.1044e-02,\n",
      "          3.1128e-02,  1.5910e-01,  5.8593e-02, -7.3880e-02,  3.6378e-01,\n",
      "         -2.9995e-01,  2.9848e-01, -6.3425e-01, -6.0793e-02, -5.5621e-03,\n",
      "         -1.3597e-01,  6.1545e-02, -3.1256e-01,  3.4049e-01,  2.7718e-01,\n",
      "         -4.7705e-01,  3.6277e-02,  1.0950e-01,  1.4379e-01,  1.5785e-01,\n",
      "         -4.4875e-01, -2.0783e-01,  7.7701e-02,  2.9658e-01,  8.9938e-02,\n",
      "         -2.1133e-01,  2.7131e-01,  3.1719e-01,  2.7609e-02, -1.7973e-01,\n",
      "          5.9684e-03,  4.1387e-02,  1.1109e-01, -2.6765e-02, -2.4972e-01,\n",
      "          1.5233e-01,  2.4316e-01, -3.5169e-01,  1.0944e-01,  1.5741e-01,\n",
      "          7.4972e-02, -1.0605e-01, -6.5436e-02,  3.2089e-02,  1.7366e-01,\n",
      "         -1.4564e-01, -2.9631e-01,  1.5712e-01, -1.5062e-01, -8.0404e-02,\n",
      "          2.4451e-02, -2.4685e-01, -3.6372e-01, -3.5911e-01, -3.9640e-01,\n",
      "         -5.0560e-02,  9.1039e-02, -2.5769e-01,  8.7016e-02, -9.7981e-02,\n",
      "         -2.8209e-01, -2.9744e-01, -1.5467e-01, -2.8777e-01, -2.1884e-01,\n",
      "          8.5424e-02, -1.2311e-01,  1.8613e-01, -3.6870e-01,  3.2827e-01,\n",
      "          6.5180e-03, -1.0124e-01, -3.0233e-02,  4.9712e-01, -2.7281e-01,\n",
      "         -4.3963e-01, -1.3805e-02,  5.7333e-01,  1.2888e-01,  3.4994e-01,\n",
      "         -2.9940e-02, -2.8154e-01, -2.0262e-01, -1.5960e-01, -2.2949e-01,\n",
      "         -9.9975e-02,  3.1818e-01, -8.5370e-02, -1.4891e-01,  4.5634e-02,\n",
      "          3.2858e-01,  2.0558e-01, -3.2889e-01, -5.2556e-02, -1.3673e-01,\n",
      "          2.0181e-01,  1.9583e-01,  3.0041e-02, -2.8890e-01,  2.1830e-02,\n",
      "         -2.5960e-02, -2.4605e-02, -1.3666e-01, -1.3044e-01, -1.4219e-02,\n",
      "         -2.0197e-01,  8.4483e-02, -3.6561e-01, -2.9257e-01,  1.6533e-01,\n",
      "          2.7783e-01, -2.9975e-01,  9.7708e-02, -1.8198e-01,  8.3758e-02,\n",
      "          2.4306e-02, -8.9654e-02, -2.4316e-01,  8.9832e-02, -9.9053e-02,\n",
      "         -6.1417e-02, -1.2992e-01, -1.6059e-01,  2.4493e-01,  7.5422e-02,\n",
      "          1.8585e-01,  1.1573e-01,  1.6440e-01, -1.5593e-01,  4.0691e-01,\n",
      "         -1.8043e-01,  3.4057e-01,  1.2766e-01]], device='cuda:1',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Retrieved chunk: \n",
      "Paris is the capital of France. It is known for its art, fashion, and culture.\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Retrieve the most relevant chunk (simplified)\n",
    "similarities = [torch.cosine_similarity(query_embedding, chunk_embedding) for chunk_embedding in chunk_embeddings]\n",
    "retrieved_chunk = chunks[torch.argmax(torch.tensor(similarities))]\n",
    "print(similarities)\n",
    "print(chunk_embeddings[torch.argmax(torch.tensor(similarities))])\n",
    "print(query_embedding)\n",
    "print(\"Retrieved chunk:\", retrieved_chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    2,     0,  2264,    16,     5,   812,     9,  1470,   116,  1437,\n",
      "         46303, 42199, 42593, 32826,     6,  1470,  1437, 46303, 36440,     2]],\n",
      "       device='cuda:1')\n",
      "What is the capital of France? ___________________________________________________________________________________Paris, France ________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_ids = generator_tokenizer(query + \" \" + retrieved_chunk, return_tensors='pt').input_ids.to(device)\n",
    "output_ids = generator.generate(input_ids)\n",
    "response = generator_tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "print(output_ids)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mad-rag-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
